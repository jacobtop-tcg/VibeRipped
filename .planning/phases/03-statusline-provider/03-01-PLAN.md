---
phase: 03-statusline-provider
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - lib/statusline/stdin.js
  - lib/statusline/detection.js
  - lib/statusline/format.js
  - test/statusline.test.js
autonomous: true

must_haves:
  truths:
    - "stdin JSON is buffered and parsed into a JavaScript object without throwing on invalid input"
    - "Process detection returns true only when current_usage is non-null with positive token counts"
    - "Exercise prompt is formatted with ANSI cyan bold and reset codes"
    - "Empty string returned when not processing or on cooldown"
    - "Null/undefined/malformed stdin data never crashes the modules"
  artifacts:
    - path: "lib/statusline/stdin.js"
      provides: "JSON stdin buffering and parsing"
      exports: ["parseStdin"]
    - path: "lib/statusline/detection.js"
      provides: "Process detection heuristic"
      exports: ["isProcessing"]
    - path: "lib/statusline/format.js"
      provides: "ANSI color formatting for exercise prompts"
      exports: ["formatExercise", "ANSI"]
    - path: "test/statusline.test.js"
      provides: "Unit tests for all three statusline modules"
      min_lines: 60
  key_links:
    - from: "lib/statusline/detection.js"
      to: "context_window.current_usage"
      via: "null check and token count check"
      pattern: "current_usage.*null"
    - from: "lib/statusline/format.js"
      to: "ANSI escape sequences"
      via: "template literal with escape codes"
      pattern: "\\\\x1b\\["
---

<objective>
Build and test the three statusline library modules: stdin JSON parsing, process detection heuristic, and ANSI exercise formatting.

Purpose: These modules are the testable core of the statusline provider. Each has well-defined input/output contracts ideal for TDD. Getting detection right is critical since the heuristic determines when exercises appear.

Output: Three tested modules in lib/statusline/ ready for integration in Plan 02.
</objective>

<execution_context>
@/Users/jacob/.claude/get-shit-done/workflows/execute-plan.md
@/Users/jacob/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/03-statusline-provider/03-RESEARCH.md
@engine.js
</context>

<tasks>

<task type="auto">
  <name>Task 1: RED - Write failing tests for statusline modules</name>
  <files>test/statusline.test.js</files>
  <action>
Create test/statusline.test.js using Node.js built-in test runner (node:test + node:assert/strict). Write tests for three modules that do not yet exist. Tests MUST fail on first run.

**stdin.js tests (parseStdin group):**
1. Parses valid JSON string into object
2. Returns null for empty string input
3. Returns null for malformed JSON (no throw)
4. Returns null for non-string input (undefined, null, number)

Test via: `const { parseStdin } = require('../lib/statusline/stdin');`
Call parseStdin(rawString) directly (synchronous parsing, NOT event-based).
The function takes a raw string (already buffered) and returns parsed object or null.

**detection.js tests (isProcessing group):**
1. Returns true when current_usage has input_tokens > 0
2. Returns true when current_usage has cache_read_input_tokens > 0
3. Returns false when current_usage is null (pre-first-API-call state)
4. Returns false when current_usage is undefined
5. Returns false when context_window is missing entirely
6. Returns false when current_usage has all zero tokens ({input_tokens: 0, cache_read_input_tokens: 0})
7. Returns false for null/undefined input data

Test via: `const { isProcessing } = require('../lib/statusline/detection');`
Call isProcessing(claudeData) with the full stdin JSON object.

**format.js tests (formatExercise group):**
1. Wraps exercise name and reps in cyan bold ANSI codes: `\x1b[36m\x1b[1m{name} x{reps}\x1b[0m`
2. Returns empty string when exercise is null/undefined
3. Handles exercise with only name (no reps) gracefully
4. Exported ANSI object contains reset, cyan, bold keys

Test via: `const { formatExercise, ANSI } = require('../lib/statusline/format');`
Call formatExercise(exerciseName, reps) with primitive arguments (not exercise object -- keep format module decoupled from engine types).

Total: ~15 test cases across 3 describe blocks.
  </action>
  <verify>
Run `node --test test/statusline.test.js` from project root. ALL tests must FAIL (module not found errors). Zero passes expected.
  </verify>
  <done>test/statusline.test.js exists with 15 test cases, all failing because lib/statusline/*.js files do not exist yet.</done>
</task>

<task type="auto">
  <name>Task 2: GREEN - Implement statusline modules to pass all tests</name>
  <files>lib/statusline/stdin.js, lib/statusline/detection.js, lib/statusline/format.js</files>
  <action>
Create lib/statusline/ directory and implement three modules. Write minimal code to pass all tests.

**lib/statusline/stdin.js:**
```javascript
function parseStdin(raw) {
  if (typeof raw !== 'string' || raw.length === 0) return null;
  try {
    return JSON.parse(raw);
  } catch {
    return null;
  }
}
module.exports = { parseStdin };
```

**lib/statusline/detection.js:**
```javascript
function isProcessing(claudeData) {
  if (!claudeData) return false;
  const currentUsage = claudeData.context_window?.current_usage;
  if (currentUsage === null || currentUsage === undefined) return false;
  return (currentUsage.input_tokens > 0 || currentUsage.cache_read_input_tokens > 0);
}
module.exports = { isProcessing };
```

Key: Use explicit null AND undefined checks (not just falsy). Zero tokens means "session started but no processing yet" -- return false. Positive tokens means active/recent processing -- return true. This is the MEDIUM confidence heuristic from research; empirical validation happens in Plan 02 checkpoint.

**lib/statusline/format.js:**
```javascript
const ANSI = {
  reset: '\x1b[0m',
  cyan: '\x1b[36m',
  bold: '\x1b[1m',
};

function formatExercise(name, reps) {
  if (!name) return '';
  if (reps === undefined || reps === null) return `${ANSI.cyan}${ANSI.bold}${name}${ANSI.reset}`;
  return `${ANSI.cyan}${ANSI.bold}${name} x${reps}${ANSI.reset}`;
}
module.exports = { formatExercise, ANSI };
```

Key: formatExercise takes (name, reps) primitives, NOT an exercise object. This decouples format from engine internals. The caller (statusline.js in Plan 02) extracts name/reps from the engine response and passes them in.

Each module uses CommonJS (matching existing codebase). Zero external dependencies.
  </action>
  <verify>
Run `node --test test/statusline.test.js` from project root. ALL tests must PASS. Then run `node --test` to verify zero regression on existing 43 tests.
  </verify>
  <done>All ~15 statusline tests pass. All 43 existing tests still pass. Three modules export correct functions.</done>
</task>

</tasks>

<verification>
1. `node --test test/statusline.test.js` -- all statusline tests pass
2. `node --test` -- all 43+ tests pass (zero regression)
3. `node -e "const s = require('./lib/statusline/stdin'); console.log(typeof s.parseStdin)"` -- "function"
4. `node -e "const d = require('./lib/statusline/detection'); console.log(typeof d.isProcessing)"` -- "function"
5. `node -e "const f = require('./lib/statusline/format'); console.log(typeof f.formatExercise, Object.keys(f.ANSI))"` -- "function ['reset','cyan','bold']"
</verification>

<success_criteria>
- lib/statusline/stdin.js exports parseStdin that safely parses JSON strings
- lib/statusline/detection.js exports isProcessing that returns true only for non-null current_usage with positive tokens
- lib/statusline/format.js exports formatExercise that wraps text in cyan bold ANSI codes
- All unit tests pass, all existing tests pass (zero regression)
</success_criteria>

<output>
After completion, create `.planning/phases/03-statusline-provider/03-01-SUMMARY.md`
</output>
